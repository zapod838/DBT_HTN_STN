{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4507813-655d-4c69-a639-24e86e6818c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nRequirement already satisfied: lightgbm in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (4.5.0)\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.9/site-packages (from lightgbm) (1.7.3)\nRequirement already satisfied: numpy>=1.17.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from lightgbm) (1.26.4)\nCollecting numpy>=1.17.0\n  Downloading numpy-1.22.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\nInstalling collected packages: numpy\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.22.4 which is incompatible.\nSuccessfully installed numpy-1.22.4\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5354b95e-5752-47fe-af5a-ebf0b10d8e14",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nRequirement already satisfied: mlflow in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (2.15.1)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from mlflow) (2.0.32)\nRequirement already satisfied: graphene<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from mlflow) (3.3)\nRequirement already satisfied: scipy<2 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (1.7.3)\nRequirement already satisfied: gunicorn<23 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from mlflow) (22.0.0)\nRequirement already satisfied: docker<8,>=4.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from mlflow) (7.1.0)\nRequirement already satisfied: numpy<2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from mlflow) (1.22.4)\nRequirement already satisfied: pyarrow<16,>=4.0.0 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (7.0.0)\nRequirement already satisfied: Flask<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from mlflow) (3.0.3)\nRequirement already satisfied: scikit-learn<2 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (1.0.2)\nRequirement already satisfied: querystring-parser<2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from mlflow) (1.2.4)\nRequirement already satisfied: markdown<4,>=3.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from mlflow) (3.7)\nRequirement already satisfied: pandas<3 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (1.4.2)\nRequirement already satisfied: mlflow-skinny==2.15.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from mlflow) (2.15.1)\nRequirement already satisfied: alembic!=1.10.0,<2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from mlflow) (1.13.2)\nRequirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (3.5.1)\nRequirement already satisfied: Jinja2<4,>=2.11 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from mlflow) (3.1.4)\nRequirement already satisfied: gitpython<4,>=3.1.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from mlflow-skinny==2.15.1->mlflow) (3.1.43)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from mlflow-skinny==2.15.1->mlflow) (0.5.1)\nRequirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from mlflow-skinny==2.15.1->mlflow) (7.2.1)\nRequirement already satisfied: requests<3,>=2.17.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from mlflow-skinny==2.15.1->mlflow) (2.32.3)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from mlflow-skinny==2.15.1->mlflow) (1.26.0)\nRequirement already satisfied: click<9,>=7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from mlflow-skinny==2.15.1->mlflow) (8.1.7)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from mlflow-skinny==2.15.1->mlflow) (1.26.0)\nRequirement already satisfied: entrypoints<1 in /databricks/python3/lib/python3.9/site-packages (from mlflow-skinny==2.15.1->mlflow) (0.4)\nRequirement already satisfied: protobuf<6,>=3.12.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from mlflow-skinny==2.15.1->mlflow) (4.25.4)\nRequirement already satisfied: cloudpickle<4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from mlflow-skinny==2.15.1->mlflow) (3.0.0)\nRequirement already satisfied: pytz<2025 in /databricks/python3/lib/python3.9/site-packages (from mlflow-skinny==2.15.1->mlflow) (2021.3)\nRequirement already satisfied: pyyaml<7,>=5.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from mlflow-skinny==2.15.1->mlflow) (6.0.2)\nRequirement already satisfied: databricks-sdk<1,>=0.20.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from mlflow-skinny==2.15.1->mlflow) (0.30.0)\nRequirement already satisfied: cachetools<6,>=5.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from mlflow-skinny==2.15.1->mlflow) (5.5.0)\nRequirement already satisfied: packaging<25 in /databricks/python3/lib/python3.9/site-packages (from mlflow-skinny==2.15.1->mlflow) (21.3)\nRequirement already satisfied: typing-extensions>=4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\nRequirement already satisfied: Mako in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.5)\nRequirement already satisfied: google-auth~=2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.15.1->mlflow) (2.34.0)\nRequirement already satisfied: urllib3>=1.26.0 in /databricks/python3/lib/python3.9/site-packages (from docker<8,>=4.0.0->mlflow) (1.26.9)\nRequirement already satisfied: blinker>=1.6.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from Flask<4->mlflow) (1.8.2)\nRequirement already satisfied: Werkzeug>=3.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from Flask<4->mlflow) (3.0.3)\nRequirement already satisfied: itsdangerous>=2.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from Flask<4->mlflow) (2.2.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.15.1->mlflow) (4.0.11)\nRequirement already satisfied: smmap<6,>=3.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.15.1->mlflow) (5.0.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.15.1->mlflow) (4.9)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.15.1->mlflow) (0.4.0)\nRequirement already satisfied: graphql-core<3.3,>=3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from graphene<4->mlflow) (3.2.3)\nRequirement already satisfied: graphql-relay<3.3,>=3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from graphene<4->mlflow) (3.2.0)\nRequirement already satisfied: aniso8601<10,>=8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from graphene<4->mlflow) (9.0.1)\nRequirement already satisfied: zipp>=0.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow-skinny==2.15.1->mlflow) (3.20.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.5)\nRequirement already satisfied: pyparsing>=2.2.1 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (3.0.4)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (0.11.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (1.3.2)\nRequirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (9.0.1)\nRequirement already satisfied: python-dateutil>=2.7 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (2.8.2)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (4.25.0)\nRequirement already satisfied: deprecated>=1.2.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.15.1->mlflow) (1.2.14)\nRequirement already satisfied: wrapt<2,>=1.10 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.15.1->mlflow) (1.16.0)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.47b0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.15.1->mlflow) (0.47b0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.15.1->mlflow) (0.6.0)\nRequirement already satisfied: six>=1.5 in /databricks/python3/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib<4->mlflow) (1.16.0)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.15.1->mlflow) (2021.10.8)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.15.1->mlflow) (3.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.15.1->mlflow) (2.0.4)\nRequirement already satisfied: joblib>=0.11 in /databricks/python3/lib/python3.9/site-packages (from scikit-learn<2->mlflow) (1.1.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from scikit-learn<2->mlflow) (2.2.0)\nRequirement already satisfied: greenlet!=0.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.3)\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d30b2268-c330-46e0-8815-12d4f4b3e556",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nRequirement already satisfied: xgboost in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (2.1.1)\nRequirement already satisfied: nvidia-nccl-cu12 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from xgboost) (2.22.3)\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.9/site-packages (from xgboost) (1.7.3)\nRequirement already satisfied: numpy in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from xgboost) (1.22.4)\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e5e1245-c6da-479e-ba0f-0169bf30e6c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nRequirement already satisfied: tensorflow in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (2.17.0)\nRequirement already satisfied: keras>=3.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from tensorflow) (3.5.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from tensorflow) (0.37.1)\nCollecting numpy<2.0.0,>=1.23.5\n  Using cached numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\nRequirement already satisfied: typing-extensions>=3.6.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from tensorflow) (4.12.2)\nRequirement already satisfied: setuptools in /databricks/python3/lib/python3.9/site-packages (from tensorflow) (61.2.0)\nRequirement already satisfied: absl-py>=1.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from tensorflow) (2.1.0)\nRequirement already satisfied: wrapt>=1.11.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from tensorflow) (4.25.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from tensorflow) (0.6.0)\nRequirement already satisfied: tensorboard<2.18,>=2.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from tensorflow) (2.17.1)\nRequirement already satisfied: termcolor>=1.1.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from tensorflow) (0.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: h5py>=3.10.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from tensorflow) (3.11.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from tensorflow) (1.65.5)\nRequirement already satisfied: requests<3,>=2.21.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.9/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: six>=1.12.0 in /databricks/python3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: flatbuffers>=24.3.25 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from tensorflow) (24.3.25)\nRequirement already satisfied: libclang>=13.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /databricks/python3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\nRequirement already satisfied: namex in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from keras>=3.2.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from keras>=3.2.0->tensorflow) (0.12.1)\nRequirement already satisfied: rich in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from keras>=3.2.0->tensorflow) (13.7.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.9)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2021.10.8)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\nRequirement already satisfied: markdown>=2.6.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\nRequirement already satisfied: importlib-metadata>=4.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.18,>=2.17->tensorflow) (7.2.1)\nRequirement already satisfied: zipp>=0.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.18,>=2.17->tensorflow) (3.20.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /databricks/python3/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.4)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\nRequirement already satisfied: mdurl~=0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\nInstalling collected packages: numpy\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.22.4\n    Uninstalling numpy-1.22.4:\n      Successfully uninstalled numpy-1.22.4\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nscipy 1.7.3 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.26.4 which is incompatible.\nSuccessfully installed numpy-1.26.4\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35a0b604-57b3-4532-964e-42c4742e32cb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/dbfs/FileStore/processed_data/STN_df_encoded.csv/</td><td>STN_df_encoded.csv/</td><td>0</td><td>0</td></tr><tr><td>dbfs:/dbfs/FileStore/processed_data/STN_df_encoded.parquet/</td><td>STN_df_encoded.parquet/</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/dbfs/FileStore/processed_data/STN_df_encoded.csv/",
         "STN_df_encoded.csv/",
         0,
         0
        ],
        [
         "dbfs:/dbfs/FileStore/processed_data/STN_df_encoded.parquet/",
         "STN_df_encoded.parquet/",
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs ls dbfs/FileStore/processed_data/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94d6f5fb-8d92-4044-a7c5-431085b455f6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PAT_ID</th>\n",
       "      <th>mpr</th>\n",
       "      <th>mpr80</th>\n",
       "      <th>MAX_GAP_IND</th>\n",
       "      <th>DS_nm</th>\n",
       "      <th>fills_nm</th>\n",
       "      <th>claim_90D_nm</th>\n",
       "      <th>claims_nm</th>\n",
       "      <th>percent_90D_nm</th>\n",
       "      <th>gpi10_cnt_nm</th>\n",
       "      <th>...</th>\n",
       "      <th>PREDOMINANT_RACE_BLACK</th>\n",
       "      <th>PREDOMINANT_RACE_HISPANIC</th>\n",
       "      <th>PREDOMINANT_RACE_OTHER RACE</th>\n",
       "      <th>PREDOMINANT_RACE_WHITE</th>\n",
       "      <th>URBANICITY_RURAL</th>\n",
       "      <th>URBANICITY_SUBURBAN</th>\n",
       "      <th>URBANICITY_URBAN</th>\n",
       "      <th>URBANICITY__Missing_</th>\n",
       "      <th>total_gaps</th>\n",
       "      <th>high_copay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.094306e+10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>360</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.094306e+10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.094307e+10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.094410e+10</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.094411e+10</td>\n",
       "      <td>0.967532</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 88 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PAT_ID</th>\n      <th>mpr</th>\n      <th>mpr80</th>\n      <th>MAX_GAP_IND</th>\n      <th>DS_nm</th>\n      <th>fills_nm</th>\n      <th>claim_90D_nm</th>\n      <th>claims_nm</th>\n      <th>percent_90D_nm</th>\n      <th>gpi10_cnt_nm</th>\n      <th>...</th>\n      <th>PREDOMINANT_RACE_BLACK</th>\n      <th>PREDOMINANT_RACE_HISPANIC</th>\n      <th>PREDOMINANT_RACE_OTHER RACE</th>\n      <th>PREDOMINANT_RACE_WHITE</th>\n      <th>URBANICITY_RURAL</th>\n      <th>URBANICITY_SUBURBAN</th>\n      <th>URBANICITY_URBAN</th>\n      <th>URBANICITY__Missing_</th>\n      <th>total_gaps</th>\n      <th>high_copay</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.094306e+10</td>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>360</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-23.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.094306e+10</td>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>180</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>44.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.094307e+10</td>\n      <td>1.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>270</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.094410e+10</td>\n      <td>0.642857</td>\n      <td>0</td>\n      <td>0</td>\n      <td>90</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.094411e+10</td>\n      <td>0.967532</td>\n      <td>1</td>\n      <td>0</td>\n      <td>180</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>45.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 88 columns</p>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_path_csv = '/dbfs/FileStore/processed_data/STN_df_encoded.csv'\n",
    "\n",
    "# Load the CSV file into a Spark DataFrame\n",
    "STN_spark_df_loaded_csv = spark.read.csv(input_path_csv, header=True, inferSchema=True)\n",
    "\n",
    "# Convert the Spark DataFrame to a Pandas DataFrame\n",
    "STN_df_encoded = STN_spark_df_loaded_csv.toPandas()\n",
    "\n",
    "# Display the Pandas DataFrame\n",
    "STN_df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "469dfb9c-18ab-48ec-93c5-f0066975ad49",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Predicting Medication Adherence\n",
    "\n",
    "The primary goal of the model is to predict whether a patient is likely to adhere to their medication regimen. \n",
    "\n",
    "This is based on the mpr80 column, where:\n",
    "\n",
    "• mpr80 = 1: Indicates that the patient's Medication Possession Ratio (MPR) is 80% or higher, meaning they are adherent to their medication.\n",
    "\n",
    "• mpr80 = 0: Indicates that the patient's MPR is below 80%, meaning they are not adherent to their medication.\n",
    "\n",
    "Identifying patients who are at high risk of non-adherence (i.e., those predicted to have mpr80 = 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "647d1484-3476-426f-8223-fb06579c4f8f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [\"STN_df_encoded\"], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Adding new features\n",
    "STN_df_encoded['total_gaps'] = STN_df_encoded['gaps_bl'] + STN_df_encoded['leading_gap']\n",
    "STN_df_encoded['high_copay'] = (STN_df_encoded['copay_tc_nm'] > STN_df_encoded['copay_tc_nm'].mean()).astype(int)\n",
    "\n",
    "# Step 4: Define target and features\n",
    "X = STN_df_encoded.drop(columns=['mpr', 'mpr80', 'PAT_ID'])  # Drop unnecessary columns including mpr and mpr80\n",
    "y = STN_df_encoded['mpr80']  # Use mpr80 as the target variable\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e1f15a8-5105-4455-83c2-09bba78b9e5b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45169bdd-2253-417b-8240-2ae30d54dd7d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.9/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils.\n  warnings.warn(\"Setuptools is replacing distutils.\")\n2024/08/20 15:17:49 WARNING mlflow.models.model: Model logged without a signature. Signatures will be required for upcoming model registry features as they validate model inputs and denote the expected schema of model outputs. Please visit https://www.mlflow.org/docs/2.15.1/models.html#set-signature-on-logged-model for instructions on setting a model signature on your logged model.\n2024/08/20 15:17:50 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n2024/08/20 15:17:50 INFO mlflow.tracking._tracking_service.client: 🏃 View run XGBoost Classifier STN at: https://community.cloud.databricks.com/ml/experiments/2051286152915209/runs/5534184da99a44df9199393129bf2896.\n2024/08/20 15:17:50 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://community.cloud.databricks.com/ml/experiments/2051286152915209.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - Accuracy: 0.97, Precision: 0.99, Recall: 0.98, F1 Score: 0.99, ROC AUC Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"XGBoost Classifier STN\"):\n",
    "    # Initialize XGBoost Classifier\n",
    "    xgb_model = XGBClassifier(random_state=42)\n",
    "    \n",
    "    # Train the model\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting on test set\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(xgb_model, \"model\")\n",
    "\n",
    "    print(f\"XGBoost - Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}, ROC AUC Score: {roc_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "465542a9-401a-40fd-a7e7-4fc1ee71c9e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Number of positive: 35510, number of negative: 3529\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018713 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 5351\n[LightGBM] [Info] Number of data points in the train set: 39039, number of used features: 63\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.909603 -> initscore=2.308800\n[LightGBM] [Info] Start training from score 2.308800\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/20 15:17:57 WARNING mlflow.models.model: Model logged without a signature. Signatures will be required for upcoming model registry features as they validate model inputs and denote the expected schema of model outputs. Please visit https://www.mlflow.org/docs/2.15.1/models.html#set-signature-on-logged-model for instructions on setting a model signature on your logged model.\n2024/08/20 15:17:57 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n2024/08/20 15:17:58 INFO mlflow.tracking._tracking_service.client: 🏃 View run LightGBM Classifier STN at: https://community.cloud.databricks.com/ml/experiments/2051286152915209/runs/07bcebbe918941c18c9661504b6cfdde.\n2024/08/20 15:17:58 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://community.cloud.databricks.com/ml/experiments/2051286152915209.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM - Accuracy: 0.98, Precision: 0.99, Recall: 0.98, F1 Score: 0.99, ROC AUC Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"LightGBM Classifier STN\"):\n",
    "    # Initialize LGBM Classifier\n",
    "    lgbm_model = LGBMClassifier(random_state=42)\n",
    "    \n",
    "    # Train the model\n",
    "    lgbm_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting on test set\n",
    "    y_pred = lgbm_model.predict(X_test)\n",
    "    y_pred_proba = lgbm_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(lgbm_model, \"model\")\n",
    "\n",
    "    print(f\"LGBM - Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}, ROC AUC Score: {roc_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71215f86-6435-41f7-a2e1-758598ba119f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n2024/08/20 15:18:15 WARNING mlflow.models.model: Model logged without a signature. Signatures will be required for upcoming model registry features as they validate model inputs and denote the expected schema of model outputs. Please visit https://www.mlflow.org/docs/2.15.1/models.html#set-signature-on-logged-model for instructions on setting a model signature on your logged model.\n2024/08/20 15:18:16 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n2024/08/20 15:18:16 INFO mlflow.tracking._tracking_service.client: 🏃 View run Logistic Regression STN at: https://community.cloud.databricks.com/ml/experiments/2051286152915209/runs/2d18cb37ffda4e519a3414937b9e3cd6.\n2024/08/20 15:18:16 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://community.cloud.databricks.com/ml/experiments/2051286152915209.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Accuracy: 0.91, Precision: 0.91, Recall: 1.00, F1 Score: 0.95, ROC AUC Score: 0.82\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"Logistic Regression STN\"):\n",
    "    # Initialize Logistic Regression\n",
    "    logreg_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    \n",
    "    # Train the model\n",
    "    logreg_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting on test set\n",
    "    y_pred = logreg_model.predict(X_test)\n",
    "    y_pred_proba = logreg_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(logreg_model, \"model\")\n",
    "\n",
    "    print(f\"Logistic Regression - Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}, ROC AUC Score: {roc_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b6f2bba-a76a-4afc-a25e-8793f039c33c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/20 15:18:27 WARNING mlflow.models.model: Model logged without a signature. Signatures will be required for upcoming model registry features as they validate model inputs and denote the expected schema of model outputs. Please visit https://www.mlflow.org/docs/2.15.1/models.html#set-signature-on-logged-model for instructions on setting a model signature on your logged model.\n2024/08/20 15:18:29 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n2024/08/20 15:18:29 INFO mlflow.tracking._tracking_service.client: 🏃 View run Random Forest Classifier STN at: https://community.cloud.databricks.com/ml/experiments/2051286152915209/runs/6c718dee6e5441f8b03f1f97a0aa7fd4.\n2024/08/20 15:18:29 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://community.cloud.databricks.com/ml/experiments/2051286152915209.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Accuracy: 0.98, Precision: 1.00, Recall: 0.98, F1 Score: 0.99, ROC AUC Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"Random Forest Classifier STN\"):\n",
    "    # Initialize RandomForestClassifier\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    \n",
    "    # Train the model\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicting on test set\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(rf_model, \"model\")\n",
    "\n",
    "    print(f\"Random Forest - Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}, ROC AUC Score: {roc_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09c05a8a-43d0-4026-a065-2f7d303eaafc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-bc7d19f6-8bbc-4354-b6be-c796f63f9c54/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n976/976 - 4s - 5ms/step - accuracy: 0.8286 - auc: 0.4992 - loss: 565.6605 - val_accuracy: 0.9096 - val_auc: 0.5253 - val_loss: 0.3330\nEpoch 2/10\n976/976 - 5s - 5ms/step - accuracy: 0.8902 - auc: 0.5104 - loss: 7.0847 - val_accuracy: 0.9097 - val_auc: 0.5056 - val_loss: 0.3262\nEpoch 3/10\n976/976 - 2s - 2ms/step - accuracy: 0.9018 - auc: 0.4918 - loss: 2.2267 - val_accuracy: 0.9097 - val_auc: 0.5001 - val_loss: 0.3187\nEpoch 4/10\n976/976 - 3s - 3ms/step - accuracy: 0.9053 - auc: 0.5008 - loss: 1.0616 - val_accuracy: 0.9097 - val_auc: 0.5000 - val_loss: 0.3058\nEpoch 5/10\n976/976 - 2s - 2ms/step - accuracy: 0.9070 - auc: 0.4947 - loss: 0.6756 - val_accuracy: 0.9097 - val_auc: 0.5000 - val_loss: 0.3036\nEpoch 6/10\n976/976 - 2s - 2ms/step - accuracy: 0.9082 - auc: 0.4949 - loss: 0.4584 - val_accuracy: 0.9097 - val_auc: 0.5000 - val_loss: 0.3033\nEpoch 7/10\n976/976 - 3s - 3ms/step - accuracy: 0.9086 - auc: 0.5009 - loss: 0.4441 - val_accuracy: 0.9097 - val_auc: 0.5000 - val_loss: 0.3032\nEpoch 8/10\n976/976 - 3s - 3ms/step - accuracy: 0.9087 - auc: 0.5026 - loss: 0.4257 - val_accuracy: 0.9097 - val_auc: 0.5000 - val_loss: 0.3032\nEpoch 9/10\n976/976 - 2s - 2ms/step - accuracy: 0.9091 - auc: 0.4917 - loss: 0.3466 - val_accuracy: 0.9097 - val_auc: 0.5000 - val_loss: 0.3032\nEpoch 10/10\n976/976 - 2s - 2ms/step - accuracy: 0.9094 - auc: 0.4915 - loss: 0.3240 - val_accuracy: 0.9097 - val_auc: 0.5000 - val_loss: 0.3032\n\r\u001B[1m  1/523\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m34s\u001B[0m 67ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001B[1m 39/523\u001B[0m \u001B[32m━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 1ms/step  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001B[1m 82/523\u001B[0m \u001B[32m━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 1ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001B[1m124/523\u001B[0m \u001B[32m━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 1ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001B[1m166/523\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 1ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001B[1m208/523\u001B[0m \u001B[32m━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 1ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001B[1m252/523\u001B[0m \u001B[32m━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 1ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001B[1m295/523\u001B[0m \u001B[32m━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 1ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001B[1m336/523\u001B[0m \u001B[32m━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 1ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001B[1m379/523\u001B[0m \u001B[32m━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━\u001B[0m \u001B[1m0s\u001B[0m 1ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001B[1m416/523\u001B[0m \u001B[32m━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━\u001B[0m \u001B[1m0s\u001B[0m 1ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001B[1m457/523\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━\u001B[0m \u001B[1m0s\u001B[0m 1ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001B[1m500/523\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 1ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001B[1m523/523\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001B[1m523/523\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 1ms/step\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/20 15:19:04 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n2024/08/20 15:19:09 WARNING mlflow.models.model: Model logged without a signature. Signatures will be required for upcoming model registry features as they validate model inputs and denote the expected schema of model outputs. Please visit https://www.mlflow.org/docs/2.15.1/models.html#set-signature-on-logged-model for instructions on setting a model signature on your logged model.\n2024/08/20 15:19:10 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n2024/08/20 15:19:11 INFO mlflow.tracking._tracking_service.client: 🏃 View run Neural Network Classifier STN at: https://community.cloud.databricks.com/ml/experiments/2051286152915209/runs/1a7afbd1c0c9437bac2ccc9037212eaf.\n2024/08/20 15:19:11 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://community.cloud.databricks.com/ml/experiments/2051286152915209.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network - Accuracy: 0.91, Precision: 0.91, Recall: 1.00, F1 Score: 0.95, ROC AUC Score: 0.50\n"
     ]
    }
   ],
   "source": [
    "import mlflow.tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run(run_name=\"Neural Network Classifier STN\"):\n",
    "    # Define the neural network architecture\n",
    "    model = Sequential([\n",
    "        Dense(64, input_shape=(X_train.shape[1],), activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss=BinaryCrossentropy(),\n",
    "                  metrics=['accuracy', AUC(name='auc')])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, \n",
    "                        epochs=10, \n",
    "                        batch_size=32, \n",
    "                        validation_split=0.2,\n",
    "                        verbose=2)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_accuracy, test_auc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_proba = model.predict(X_test)\n",
    "    y_pred = (y_pred_proba > 0.5).astype(\"int32\")\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", test_accuracy)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    mlflow.log_metric(\"roc_auc\", test_auc)\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.tensorflow.log_model(model, \"model\")\n",
    "\n",
    "    print(f\"Neural Network - Accuracy: {test_accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}, ROC AUC Score: {test_auc:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2051286152915214,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "STN _Models",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
